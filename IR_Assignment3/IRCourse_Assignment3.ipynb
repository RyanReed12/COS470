{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "igqb9fy4ohub",
        "gCQQrL6HrnTK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importation, Queries, and Text Processor"
      ],
      "metadata": {
        "id": "6890MUE4sym3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 233,
      "metadata": {
        "id": "2uWyTOS6Rtmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0540f5f-6c00-42dd-cf7d-a7da0f7e219d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# importing & initializing necessities\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "import scipy\n",
        "from sklearn.metrics import ndcg_score, dcg_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from post_parser_record import PostParserRecord\n",
        "post_reader = PostParserRecord(\"Posts_Coffee.xml\")\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "MmY0lyp9ljXp"
      },
      "execution_count": 234,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this is a utility function designed to deal with raw text.\n",
        "def text_processor (input_text):\n",
        "  # remove punctuation & convert text to lowercase\n",
        "  input_text = re.sub(r\"[(,,.;@/>#//\\\\\\/^`'â€™/_//=\\\"-:?*\\[\\]<!&$)]+\\ *\", \" \", input_text.lower())\n",
        "  # text tokenized into a list\n",
        "  list_of_words = word_tokenize(input_text)\n",
        "  # list comprehension to filter out any stopwords\n",
        "  list_of_words_res = [x for x in list_of_words if (x not in stop_words) and (x != 'p')]\n",
        "  return list_of_words_res"
      ],
      "metadata": {
        "id": "fYQhh45jsCAB"
      },
      "execution_count": 235,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# queryset\n",
        "queries = {\n",
        "    \"espresso\",\n",
        "    \"turkish coffee\",\n",
        "    \"making a decaffeinated coffee\",\n",
        "    \"can I use the same coffee grounds twice?\",\n",
        "}"
      ],
      "metadata": {
        "id": "A-cm9pKrrueR"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# TF-IDF Model"
      ],
      "metadata": {
        "id": "9L92URSyoRv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF\n",
        "# 1) create TF such that tf_dict -> Term : (Doc : TF)\n",
        "# 2) create IDF such that idf_dict -> Term : IDF\n",
        "# 3) Handle query, return tf-idf score"
      ],
      "metadata": {
        "id": "Yvbj_maPqbnu"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function builds the term frequency dictionary.\n",
        "def build_TF():\n",
        "    tf_dict = dict() # this will hold the result\n",
        "    for post in post_reader.map_questions: # going over questions\n",
        "      question_text = post_reader.map_questions[post].title + \" \" + post_reader.map_questions[post].body # joining question text\n",
        "      question_text = text_processor(question_text) # processing the question text\n",
        "      currentPost_ID = post_reader.map_questions[post].post_id # getting the document id\n",
        "      for term in question_text:\n",
        "        if term not in tf_dict:\n",
        "          tf_dict[term] = dict()\n",
        "        if currentPost_ID not in tf_dict[term]:\n",
        "          tf_dict[term][currentPost_ID] = 1/len(question_text)\n",
        "        tf_dict[term][currentPost_ID] += 1/len(question_text)\n",
        "\n",
        "    for post in post_reader.map_just_answers: # going over answers\n",
        "      answer_text = post_reader.map_just_answers[post].body # joining question text\n",
        "      answer_text = text_processor(answer_text) # processing the question text\n",
        "      currentPost_ID = post_reader.map_just_answers[post].post_id # getting the document id\n",
        "      for term in answer_text:\n",
        "        if term not in tf_dict:\n",
        "          tf_dict[term] = dict()\n",
        "        if currentPost_ID not in tf_dict[term]:\n",
        "          tf_dict[term][currentPost_ID] = 1/len(answer_text)\n",
        "        tf_dict[term][currentPost_ID] += 1/len(answer_text)\n",
        "    return OrderedDict(sorted(tf_dict.items()))\n",
        "\n",
        "output_file = open(\"tf.json\", \"w\")\n",
        "json.dump(build_TF(), output_file)\n",
        "output_file.close()"
      ],
      "metadata": {
        "id": "cM2aosI_tPSV"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these are helper functions to gather the total number of posts\n",
        "def total_posts():\n",
        "  total = 0\n",
        "  for post in post_reader.map_questions:\n",
        "    total += 1\n",
        "  for post in post_reader.map_just_answers:\n",
        "    total += 1\n",
        "  return total\n",
        "N = total_posts()\n",
        "\n",
        "# we also load the tf dictionary back up for a convient way to find df\n",
        "with open('tf.json') as tf_file:\n",
        "  tf_data = json.load(tf_file)\n"
      ],
      "metadata": {
        "id": "P9FkoB8Ur6ls"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function builds the inverse document frequency dictionary.\n",
        "def inverse_df():\n",
        "  idf_dict = dict()\n",
        "  for term in tf_data:\n",
        "    if term not in idf_dict:\n",
        "      idf_dict[term] = 0\n",
        "    idf_dict[term] = math.log2(N / len(tf_data[term].keys()))\n",
        "  return OrderedDict(sorted(idf_dict.items()))\n",
        "\n",
        "# writing out file\n",
        "output_file = open(\"idf.json\", \"w\")\n",
        "json.dump(inverse_df(), output_file)\n",
        "output_file.close()\n",
        "\n",
        "# reading in file\n",
        "with open('idf.json') as idf_file:\n",
        "  idf_data = json.load(idf_file)"
      ],
      "metadata": {
        "id": "Nol0qjnhrmD5"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function computes a TF-IDF dictionary\n",
        "def build_tf_idf():\n",
        "  tf_idf_dict = dict()\n",
        "  for term in tf_data:\n",
        "    for doc in tf_data[term]:\n",
        "      if term not in tf_idf_dict:\n",
        "        tf_idf_dict[term] = dict()\n",
        "      temp_dict = {doc: tf_data[term][doc]*idf_data[term]}\n",
        "      tf_idf_dict[term].update(temp_dict)\n",
        "  return tf_idf_dict\n",
        "\n",
        "# writing out file\n",
        "output_file = open(\"tf_idf.json\", \"w\")\n",
        "json.dump(build_tf_idf(), output_file)\n",
        "output_file.close()\n",
        "\n",
        "# reading in file\n",
        "with open('tf_idf.json') as tf_idf_file:\n",
        "  tf_idf_data = json.load(tf_idf_file)"
      ],
      "metadata": {
        "id": "PzpvKU_Tw7f-"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query handler\n",
        "def query_handler_tfidf(query):\n",
        "  query_terms = text_processor(query)\n",
        "  list_of_docs = dict()\n",
        "  for term in query_terms:\n",
        "    if term in tf_idf_data:\n",
        "      doc_ids = tf_idf_data[term]\n",
        "      for doc in doc_ids:\n",
        "        if doc not in list_of_docs:\n",
        "          list_of_docs.update(doc_ids)\n",
        "        else:\n",
        "          list_of_docs[doc] += doc_ids[doc]\n",
        "  return dict((list((dict(sorted(list_of_docs.items(), key=lambda element: element[1], reverse=True))).items())[:5]))"
      ],
      "metadata": {
        "id": "X_7FST_P17cO"
      },
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_handler_tfidf(\"espresso\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ8_p6T421yZ",
        "outputId": "aebba612-a245-4de5-b75f-86caf22e5baf"
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'3904': 1.4571853159493842,\n",
              " '4404': 1.311466784354446,\n",
              " '3168': 1.0928889869620382,\n",
              " '2867': 0.9714568772995894,\n",
              " '93': 0.9367619888246042}"
            ]
          },
          "metadata": {},
          "execution_count": 243
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector Space Model"
      ],
      "metadata": {
        "id": "igqb9fy4ohub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all terms in collection, and all unique terms\n",
        "def get_terms():\n",
        "  terms = list()\n",
        "  for post in post_reader.map_questions: # going over questions\n",
        "      question_text = post_reader.map_questions[post].title + \" \" + post_reader.map_questions[post].body # joining question text\n",
        "      question_text = text_processor(question_text) # processing the question text\n",
        "      for term in question_text:\n",
        "        terms.append(term)\n",
        "\n",
        "  for post in post_reader.map_just_answers: # going over answers\n",
        "    answer_text = post_reader.map_just_answers[post].body # joining question text\n",
        "    answer_text = text_processor(answer_text) # processing the question text\n",
        "    for term in answer_text:\n",
        "      terms.append(term)\n",
        "      \n",
        "  return terms\n",
        "\n",
        "terms = get_terms()\n",
        "num_terms = len(terms)\n",
        "num_uterms = len(set(terms))\n",
        "\n",
        "print(\"Total number of terms:\", num_terms, \"\\nTotal number of unique terms:\", num_uterms)\n",
        "\n",
        "# creating a dictionary for terms\n",
        "term_dict = dict()\n",
        "index = 0\n",
        "for term in set(terms):\n",
        "  term_dict[term] = index\n",
        "  index += 1\n",
        "# this function houses the bulk of the vsm algorithm\n",
        "def vsm():\n",
        "  doc_vectors = dict()\n",
        "  for post in post_reader.map_questions: # going over the question posts\n",
        "    vector = np.zeros(num_uterms)\n",
        "    question_text = post_reader.map_questions[post].title + \" \" + post_reader.map_questions[post].body # joining question text\n",
        "    question_text = text_processor(question_text) # processing the question text\n",
        "    currentPost_ID = post_reader.map_questions[post].post_id # getting the document id\n",
        "    for term in question_text:\n",
        "      if term in term_dict:\n",
        "        vector[term_dict[term]] += 1\n",
        "    doc_vectors[currentPost_ID] = vector\n",
        "\n",
        "  for post in post_reader.map_just_answers: # going over the answer posts\n",
        "    vector = np.zeros(num_uterms)\n",
        "    answer_text = post_reader.map_just_answers[post].body # getting answer text\n",
        "    answer_text = text_processor(answer_text) # processing the answer text\n",
        "    currentPost_ID = post_reader.map_just_answers[post].post_id # getting the document id\n",
        "    for term in answer_text:\n",
        "      if term in term_dict:\n",
        "        vector[term_dict[term]] += 1\n",
        "    doc_vectors[currentPost_ID] = vector\n",
        "  return doc_vectors\n",
        "\n",
        "vectors_dict = vsm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZlFKvlcw9Zjm",
        "outputId": "a375ad9a-52dd-40bc-de68-703042c24a1a"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of terms: 344882 \n",
            "Total number of unique terms: 18372\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# query handling for vsm\n",
        "def query_handler_vsm(query):\n",
        "  query_terms = text_processor(query)\n",
        "  q_vector = np.zeros(num_uterms)\n",
        "  for term in query_terms:\n",
        "    if term in term_dict:\n",
        "      q_vector[term_dict[term]] += 1\n",
        "\n",
        "  results_dict = dict()\n",
        "  for doc in vectors_dict:\n",
        "    results_dict[doc] = 1 - scipy.spatial.distance.cosine(q_vector, vectors_dict[doc])\n",
        "  return dict((list(dict(sorted(results_dict.items(), key=lambda element: element[1], reverse=True)).items())[:5]))"
      ],
      "metadata": {
        "id": "1Nn4Nd1sG97a"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_handler_vsm(\"espresso\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4_A63KNOlnB",
        "outputId": "efec95b5-872e-454f-801b-a640a5fcade8"
      },
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{2766: 0.6644105970267493, 4175: 0.6401843996644798, 3168: 0.6396021490668313, 26: 0.629940788348712, 5528: 0.6155870112510924}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BM25 Model"
      ],
      "metadata": {
        "id": "gCQQrL6HrnTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  average length of documents\n",
        "avg_len = len(terms) / N\n",
        "\n",
        "# this function computes a dictionary of the length of each document\n",
        "def len_collection():\n",
        "  len_dict = dict()\n",
        "  for post in post_reader.map_questions: # going over questions\n",
        "      question_text = post_reader.map_questions[post].title + \" \" + post_reader.map_questions[post].body # joining question text\n",
        "      question_text = text_processor(question_text) # processing the question text\n",
        "      currentPost_ID = post_reader.map_questions[post].post_id # getting the document id\n",
        "      if currentPost_ID not in len_dict:\n",
        "        len_dict[currentPost_ID] = 0\n",
        "      len_dict[currentPost_ID] = len(question_text)\n",
        "  for post in post_reader.map_just_answers: # going over answers\n",
        "      answer_text = post_reader.map_just_answers[post].body # joining question text\n",
        "      answer_text = text_processor(answer_text) # processing the question text\n",
        "      currentPost_ID = post_reader.map_just_answers[post].post_id # getting the document id\n",
        "      if currentPost_ID not in len_dict:\n",
        "        len_dict[currentPost_ID] = 0\n",
        "      len_dict[currentPost_ID] = len(answer_text)\n",
        "  return len_dict\n",
        "len_dict = len_collection()"
      ],
      "metadata": {
        "id": "HbwLwT45akLr"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to perform BM25\n",
        "k1 = 1.2\n",
        "b = 0.75\n",
        "\n",
        "def query_handler_bm25(query):\n",
        "  query_terms = text_processor(query)\n",
        "  list_of_docs = dict()\n",
        "  for term in query_terms:\n",
        "    if term in tf_data:\n",
        "      for doc in tf_data[term]:\n",
        "        if doc not in list_of_docs:\n",
        "          list_of_docs[doc] = 0\n",
        "        idoc = int(doc)\n",
        "        len_eq = len_dict[idoc] / avg_len\n",
        "        top_eq = (k1 + 1) * tf_data[term][doc]\n",
        "        bot_eq = k1 * ((1-b) + b * (len_eq)) + tf_data[term][doc]\n",
        "        list_of_docs[doc] += idf_data[term] * (top_eq / bot_eq)\n",
        "  return dict((list((dict(sorted(list_of_docs.items(), key=lambda element: element[1], reverse=True))).items())[:5]))\n"
      ],
      "metadata": {
        "id": "sa9P-SFwVTKk"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_handler_bm25(\"espresso\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hck_8ZTVc1Q2",
        "outputId": "d7714caa-4033-49ae-c175-186d8d7c71b3"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'3904': 2.2994190498647242,\n",
              " '4404': 2.042602576406589,\n",
              " '3168': 1.6696453819078618,\n",
              " '93': 1.5540809001677207,\n",
              " '2867': 1.4977023874695319}"
            ]
          },
          "metadata": {},
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Discussion (Question 2)"
      ],
      "metadata": {
        "id": "YD5i_Fm-tEK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF results\n",
        "print(\"TF-IDF Results:\")\n",
        "for query in queries:\n",
        "  print(\"\\nQuery :\", query)\n",
        "  results = query_handler_tfidf(query)\n",
        "  i = 1\n",
        "  for result in results:\n",
        "    print(i, \":\", result, \"-\", results[result])\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygsDFOVMqQvg",
        "outputId": "f3fd7b2c-ad32-4ef3-c19f-6bb673aa917b"
      },
      "execution_count": 250,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Results:\n",
            "\n",
            "Query : can I use the same coffee grounds twice?\n",
            "1 : 3966 - 1.5942030004901218\n",
            "2 : 3818 - 1.5158453532697278\n",
            "3 : 2683 - 1.5004263534024675\n",
            "4 : 4703 - 1.2632044610581064\n",
            "5 : 3568 - 1.0716828097153608\n",
            "\n",
            "Query : making a decaffeinated coffee\n",
            "1 : 3225 - 1.726014751206339\n",
            "2 : 97 - 0.9643953105943388\n",
            "3 : 2867 - 0.8036627588286156\n",
            "4 : 3321 - 0.6289534634310905\n",
            "5 : 1656 - 0.6199684139535035\n",
            "\n",
            "Query : turkish coffee\n",
            "1 : 4486 - 1.7029595989046178\n",
            "2 : 3369 - 1.4596796562039582\n",
            "3 : 5690 - 0.69666529046098\n",
            "4 : 2879 - 0.6192580359653156\n",
            "5 : 4551 - 0.4541225597078981\n",
            "\n",
            "Query : espresso\n",
            "1 : 3904 - 1.4571853159493842\n",
            "2 : 4404 - 1.311466784354446\n",
            "3 : 3168 - 1.0928889869620382\n",
            "4 : 2867 - 0.9714568772995894\n",
            "5 : 93 - 0.9367619888246042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# VSM results\n",
        "print(\"VSM Results:\")\n",
        "for query in queries:\n",
        "  print(\"\\nQuery :\", query)\n",
        "  results = query_handler_vsm(query)\n",
        "  i = 1\n",
        "  for result in results:\n",
        "    print(i, \":\", result, \"-\", results[result])\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3yaxa2Prnml",
        "outputId": "0c403426-3b7a-4b72-d845-ec2e3e1c26bb"
      },
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VSM Results:\n",
            "\n",
            "Query : can I use the same coffee grounds twice?\n",
            "1 : 2683 - 0.6565321642986127\n",
            "2 : 1749 - 0.6002450479987809\n",
            "3 : 3258 - 0.5454545454545455\n",
            "4 : 5121 - 0.5388159060803248\n",
            "5 : 2609 - 0.5151021148075838\n",
            "\n",
            "Query : making a decaffeinated coffee\n",
            "1 : 120 - 0.560448538317805\n",
            "2 : 4193 - 0.501280411827603\n",
            "3 : 2158 - 0.5003702332976757\n",
            "4 : 3293 - 0.5\n",
            "5 : 204 - 0.492365963917331\n",
            "\n",
            "Query : turkish coffee\n",
            "1 : 5094 - 0.7715167498104596\n",
            "2 : 2522 - 0.7252406676228423\n",
            "3 : 3074 - 0.7071067811865476\n",
            "4 : 2379 - 0.6832312780114155\n",
            "5 : 45 - 0.649519052838329\n",
            "\n",
            "Query : espresso\n",
            "1 : 2766 - 0.6644105970267493\n",
            "2 : 4175 - 0.6401843996644798\n",
            "3 : 3168 - 0.6396021490668313\n",
            "4 : 26 - 0.629940788348712\n",
            "5 : 5528 - 0.6155870112510924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BM25 results\n",
        "print(\"BM25 Results:\")\n",
        "for query in queries:\n",
        "  print(\"\\nQuery :\", query)\n",
        "  results = query_handler_bm25(query)\n",
        "  i = 1\n",
        "  for result in results:\n",
        "    print(i, \":\", result, \"-\", results[result])\n",
        "    i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwnjMxc5rufW",
        "outputId": "adfea045-3233-41cb-cd0b-b9879686c671"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BM25 Results:\n",
            "\n",
            "Query : can I use the same coffee grounds twice?\n",
            "1 : 3966 - 3.982112714577462\n",
            "2 : 1749 - 3.384308239743852\n",
            "3 : 2683 - 3.360534880339401\n",
            "4 : 5121 - 2.3823629682447676\n",
            "5 : 4149 - 2.2385955631336705\n",
            "\n",
            "Query : making a decaffeinated coffee\n",
            "1 : 204 - 5.884320197351069\n",
            "2 : 3293 - 5.332624717914693\n",
            "3 : 2897 - 3.244946523493822\n",
            "4 : 3225 - 3.1908449708781115\n",
            "5 : 120 - 2.6304449823904488\n",
            "\n",
            "Query : turkish coffee\n",
            "1 : 5182 - 6.372043626061505\n",
            "2 : 5094 - 5.540444119684456\n",
            "3 : 483 - 4.139037461760955\n",
            "4 : 209 - 3.638937818625787\n",
            "5 : 2522 - 3.333600118754522\n",
            "\n",
            "Query : espresso\n",
            "1 : 3904 - 2.2994190498647242\n",
            "2 : 4404 - 2.042602576406589\n",
            "3 : 3168 - 1.6696453819078618\n",
            "4 : 93 - 1.5540809001677207\n",
            "5 : 2867 - 1.4977023874695319\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TF-IDF relevancies\n",
        "relevancies_tfidf = [\n",
        "    [0, 0, 1, 0, 0],\n",
        "    [1, 0, 0, 0, 0],\n",
        "    [1, 0, 1, 0, 0],\n",
        "    [1, 1, 1, 1, 1]\n",
        "]\n",
        "print(\"TF-IDF Precision at 5 :\", ((1 + 1 + 2 + 5)/5)/5)\n",
        "\n",
        "#computing tf-idf ndcg\n",
        "ideal_order_relevancies = [sorted(item, reverse=True) for item in relevancies_tfidf]\n",
        "ndcg_list = list()\n",
        "\n",
        "for ideal, relevance in zip(ideal_order_relevancies, relevancies_tfidf):\n",
        "  ndcg_list.append(ndcg_score(np.array([ideal]), np.array([relevance])))\n",
        "\n",
        "print(\"TF-IDF nDCG at 5 :\", (sum(ndcg_list) / len(ndcg_list)))\n",
        "\n",
        "# VSM relevancies\n",
        "relevancies_vsm = [\n",
        "    [1, 1, 1, 0, 1],\n",
        "    [1, 1, 0, 1, 1],\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1]\n",
        "]\n",
        "\n",
        "print(\"\\nVSM Precision at 5 :\", ((4 + 4 + 5 + 5)/5)/5)\n",
        "\n",
        "#computing vsm ndcg\n",
        "ideal_order_relevancies = [sorted(item, reverse=True) for item in relevancies_vsm]\n",
        "ndcg_list = list()\n",
        "\n",
        "for ideal, relevance in zip(ideal_order_relevancies, relevancies_vsm):\n",
        "  ndcg_list.append(ndcg_score(np.array([ideal]), np.array([relevance])))\n",
        "\n",
        "print(\"VSM nDCG at 5 :\", (sum(ndcg_list) / len(ndcg_list)))\n",
        "\n",
        "# BM25 relevancies\n",
        "relevancies_bm25 = [\n",
        "    [0, 1, 1, 0, 0],\n",
        "    [1, 0, 1, 1, 0],\n",
        "    [1, 1, 1, 1, 1],\n",
        "    [1, 1, 1, 1, 1]\n",
        "]\n",
        "print(\"\\nBM25 Precision at 5 :\", ((2 + 3 + 5 + 5)/5)/5)\n",
        "\n",
        "#computing bm25 ndcg\n",
        "ideal_order_relevancies = [sorted(item, reverse=True) for item in relevancies_bm25]\n",
        "ndcg_list = list()\n",
        "\n",
        "for ideal, relevance in zip(ideal_order_relevancies, relevancies_bm25):\n",
        "  ndcg_list.append(ndcg_score(np.array([ideal]), np.array([relevance])))\n",
        "\n",
        "print(\"BM25 nDCG at 5 :\", (sum(ndcg_list) / len(ndcg_list)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltqXESqar9Ok",
        "outputId": "72d4b16a-bf01-4bca-ec33-61fc1bb6295f"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF Precision at 5 : 0.36\n",
            "TF-IDF nDCG at 5 : 0.81409864757368\n",
            "\n",
            "VSM Precision at 5 : 0.72\n",
            "VSM nDCG at 5 : 0.9505098091139026\n",
            "\n",
            "BM25 Precision at 5 : 0.6\n",
            "BM25 nDCG at 5 : 0.9069427616901222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Of all the three models, the vector space model displayed the highest effectiveness. It had the highest precision, and nDCG, at cut 5. TF-IDF performed the worst, and had a precision of only 0.36. Despite the low precision at cut 5, it still performed quite well. Best Match 25 performed middle of the models, but was fairly close to surpassing the nDCG of the vector space model. Overall, all three models displayed no abnormalities in time efficiency, this was not specifically measured, but at a high view, all ran well below 2 seconds. Mentionable, as well as noted by way of Google Colab's UI. \n",
        "\n",
        "In terms of the low precision for the TF-IDF, the model seemed to run into issues with posts that had less specific keywords and a lower text length. An example for the query \"Can I use the same coffee grounds twice?\", was https://coffee.stackexchange.com/questions/3028/why-does-french-press-not-give-enough-caffeine-effect/3966#3966. The answer post that the model ranked as first, had non-specific keywords such as 'twice', 'use', and 'coffee', and was of a short length. Although not pertaining to this assignment, a potential solution to improve the TF-IDF algorithm would be to weight query terms differently, putting more weight onto the terms 'twice' and 'grounds'."
      ],
      "metadata": {
        "id": "qodawKK-6NVF"
      }
    }
  ]
}